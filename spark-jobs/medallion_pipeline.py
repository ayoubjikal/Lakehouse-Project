"""
Morocco Census Data Lake - Medallion Architecture Pipeline
============================================================
Main orchestrator for the Bronze â†’ Silver â†’ Gold pipeline.

Medallion Architecture:
- Bronze: Raw data ingestion from Kafka (append-only)
- Silver: Cleansed, validated, and enriched data
- Gold: Business-level aggregations for analytics

Usage:
    spark-submit medallion_pipeline.py [--mode streaming|batch]
"""

import sys
import time
import argparse
from pyspark.sql import SparkSession

# Import layer modules
from bronze_ingestion import create_bronze_tables, process_bronze_stream, get_bronze_stats
from silver_processing import create_silver_tables, process_silver_batch, process_silver_stream, get_silver_stats
from gold_aggregations import create_gold_tables, process_gold_layer, get_gold_stats


def create_spark_session():
    """Create and configure Spark session for Iceberg + Nessie"""
    
    print("ğŸ”§ Initializing Spark session...")
    
    spark = SparkSession.builder \
        .appName("Morocco Census - Medallion Pipeline") \
        .config("spark.sql.extensions",
                "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,"
                "org.projectnessie.spark.extensions.NessieSparkSessionExtensions") \
        .config("spark.sql.catalog.nessie", "org.apache.iceberg.spark.SparkCatalog") \
        .config("spark.sql.catalog.nessie.catalog-impl", "org.apache.iceberg.nessie.NessieCatalog") \
        .config("spark.sql.catalog.nessie.uri", "http://catalog:19120/api/v1") \
        .config("spark.sql.catalog.nessie.ref", "main") \
        .config("spark.sql.catalog.nessie.authentication.type", "NONE") \
        .config("spark.sql.catalog.nessie.warehouse", "s3a://bronze/") \
        .config("spark.sql.catalog.nessie.cache-enabled", "true") \
        .config("spark.sql.defaultCatalog", "nessie") \
        .config("spark.hadoop.fs.s3a.endpoint", "http://storage:9000") \
        .config("spark.hadoop.fs.s3a.access.key", "admin") \
        .config("spark.hadoop.fs.s3a.secret.key", "password") \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
        .config("spark.sql.streaming.checkpointLocation", "s3a://checkpoints/") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    
    print("âœ… Spark session initialized")
    return spark


def initialize_tables(spark: SparkSession):
    """Create all medallion layer tables"""
    
    print("\n" + "=" * 70)
    print("ğŸ“¦ INITIALIZING MEDALLION ARCHITECTURE TABLES")
    print("=" * 70)
    
    create_bronze_tables(spark)
    create_silver_tables(spark)
    create_gold_tables(spark)
    
    print("\nâœ… All medallion tables initialized")


def run_streaming_pipeline(spark: SparkSession):
    """
    Run the complete medallion pipeline in streaming mode.
    Bronze streams from Kafka, Silver reads from Bronze, Gold is computed periodically.
    """
    
    print("\n" + "=" * 70)
    print("ğŸš€ STARTING STREAMING MEDALLION PIPELINE")
    print("=" * 70)
    print("Mode: Streaming")
    print("Bronze: Kafka â†’ Iceberg (continuous)")
    print("Silver: Bronze â†’ Iceberg (micro-batch)")
    print("Gold: Silver â†’ Iceberg (periodic)")
    print("=" * 70)
    
    try:
        # Start Bronze streaming (Kafka â†’ Bronze Iceberg)
        bronze_query = process_bronze_stream(spark)
        
        # Give Bronze time to start and ingest some data
        print("\nâ³ Waiting for initial Bronze data (30 seconds)...")
        time.sleep(30)
        
        # Run initial Silver processing
        print("\nğŸ”„ Running initial Silver processing...")
        process_silver_batch(spark)
        
        # Run initial Gold processing
        print("\nğŸ”„ Running initial Gold processing...")
        process_gold_layer(spark)
        
        # Main processing loop
        gold_interval = 60  # Seconds between Gold refreshes
        silver_interval = 30  # Seconds between Silver processing
        last_silver = time.time()
        last_gold = time.time()
        
        print("\n" + "=" * 70)
        print("ğŸ”„ MEDALLION PIPELINE RUNNING")
        print(f"Bronze: Continuous streaming")
        print(f"Silver: Every {silver_interval}s")
        print(f"Gold: Every {gold_interval}s")
        print("=" * 70)
        print("Press Ctrl+C to stop...")
        
        while bronze_query.isActive:
            current_time = time.time()
            
            # Process Silver periodically
            if current_time - last_silver >= silver_interval:
                print("\nğŸ”„ Processing Silver layer...")
                process_silver_batch(spark)
                last_silver = current_time
            
            # Process Gold periodically
            if current_time - last_gold >= gold_interval:
                print("\nğŸ”„ Processing Gold layer...")
                process_gold_layer(spark)
                last_gold = current_time
            
            # Brief sleep to prevent busy waiting
            time.sleep(5)
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ Shutdown requested...")
    except Exception as e:
        print(f"âŒ Pipeline error: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        print("\nğŸ“Š Final Statistics:")
        get_bronze_stats(spark)
        get_silver_stats(spark)
        get_gold_stats(spark)
        
        if 'bronze_query' in locals() and bronze_query.isActive:
            bronze_query.stop()
        
        print("\nâœ… Pipeline stopped")


def run_batch_pipeline(spark: SparkSession):
    """
    Run the medallion pipeline in batch mode.
    Processes all layers sequentially.
    """
    
    print("\n" + "=" * 70)
    print("ğŸš€ STARTING BATCH MEDALLION PIPELINE")
    print("=" * 70)
    print("Mode: Batch")
    print("Processing: Bronze â†’ Silver â†’ Gold (sequential)")
    print("=" * 70)
    
    try:
        # Process Bronze (read from Kafka in batch mode)
        print("\nğŸ¥‰ Processing Bronze layer...")
        bronze_query = process_bronze_stream(spark)
        
        # Wait for some data
        print("â³ Ingesting data for 60 seconds...")
        time.sleep(60)
        
        # Stop Bronze streaming for batch mode
        if bronze_query and bronze_query.isActive:
            bronze_query.stop()
        
        get_bronze_stats(spark)
        
        # Process Silver
        print("\nğŸ¥ˆ Processing Silver layer...")
        process_silver_batch(spark)
        get_silver_stats(spark)
        
        # Process Gold
        print("\nğŸ¥‡ Processing Gold layer...")
        process_gold_layer(spark)
        get_gold_stats(spark)
        
        print("\n" + "=" * 70)
        print("âœ… BATCH PIPELINE COMPLETED SUCCESSFULLY")
        print("=" * 70)
        
    except Exception as e:
        print(f"âŒ Pipeline error: {str(e)}")
        import traceback
        traceback.print_exc()


def display_layer_info():
    """Display medallion architecture information"""
    
    info = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           MOROCCO CENSUS DATA LAKE - MEDALLION ARCHITECTURE           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                        â•‘
â•‘  ğŸ¥‰ BRONZE LAYER (Raw Data)                                           â•‘
â•‘  â”œâ”€â”€ Source: Kafka (census_persons_topic)                             â•‘
â•‘  â”œâ”€â”€ Target: nessie.bronze.census_persons                             â•‘
â•‘  â”œâ”€â”€ Mode: Append-only, no transformations                            â•‘
â•‘  â””â”€â”€ Contains: Raw census records with Kafka metadata                 â•‘
â•‘                                                                        â•‘
â•‘  ğŸ¥ˆ SILVER LAYER (Cleansed Data)                                      â•‘
â•‘  â”œâ”€â”€ Source: Bronze layer                                             â•‘
â•‘  â”œâ”€â”€ Target: nessie.silver.census_persons                             â•‘
â•‘  â”œâ”€â”€ Transformations:                                                 â•‘
â•‘  â”‚   â”œâ”€â”€ Data cleansing & standardization                             â•‘
â•‘  â”‚   â”œâ”€â”€ Validation & quality checks                                  â•‘
â•‘  â”‚   â”œâ”€â”€ Derived columns (age_group, income_level, etc.)              â•‘
â•‘  â”‚   â””â”€â”€ Invalid records â†’ quarantine table                           â•‘
â•‘  â””â”€â”€ Contains: Validated, enriched census records                     â•‘
â•‘                                                                        â•‘
â•‘  ğŸ¥‡ GOLD LAYER (Business Aggregations)                                â•‘
â•‘  â”œâ”€â”€ Source: Silver layer                                             â•‘
â•‘  â”œâ”€â”€ Tables:                                                          â•‘
â•‘  â”‚   â”œâ”€â”€ nessie.gold.regional_demographics                            â•‘
â•‘  â”‚   â”œâ”€â”€ nessie.gold.age_distribution                                 â•‘
â•‘  â”‚   â”œâ”€â”€ nessie.gold.employment_stats                                 â•‘
â•‘  â”‚   â”œâ”€â”€ nessie.gold.education_stats                                  â•‘
â•‘  â”‚   â”œâ”€â”€ nessie.gold.city_stats                                       â•‘
â•‘  â”‚   â””â”€â”€ nessie.gold.national_summary                                 â•‘
â•‘  â””â”€â”€ Contains: Analytics-ready aggregated data                        â•‘
â•‘                                                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(info)


def main():
    """Main entry point for the medallion pipeline"""
    
    # Parse arguments
    parser = argparse.ArgumentParser(description="Morocco Census Medallion Pipeline")
    parser.add_argument("--mode", choices=["streaming", "batch"], default="streaming",
                        help="Pipeline mode: streaming (continuous) or batch (one-time)")
    args = parser.parse_args()
    
    print("\n" + "=" * 70)
    print("ğŸ‡²ğŸ‡¦ MOROCCO CENSUS DATA LAKE")
    print("   Medallion Architecture Pipeline")
    print("=" * 70)
    
    display_layer_info()
    
    # Create Spark session
    spark = create_spark_session()
    
    try:
        # Initialize all tables
        initialize_tables(spark)
        
        # Run appropriate pipeline mode
        if args.mode == "streaming":
            run_streaming_pipeline(spark)
        else:
            run_batch_pipeline(spark)
        
    except Exception as e:
        print(f"âŒ Fatal error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        spark.stop()
        print("\nğŸ Spark session closed")


if __name__ == "__main__":
    main()
